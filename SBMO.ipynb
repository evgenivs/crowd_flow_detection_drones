{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOJzSIpUaDTY"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Conv2D, MaxPool2D, Input, Conv2DTranspose, BatchNormalization, Rescaling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input layer\n",
        "input_layer = Input(shape=(512,640,3), name='input_layer')\n",
        "x = Rescaling(scale=1/255.0)(input_layer)\n",
        "\n",
        "# Hidden layers\n",
        "x = Conv2D(filters=16, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)\n",
        "\n",
        "x = Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)\n",
        "\n",
        "x = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)\n",
        "\n",
        "x = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)\n",
        "\n",
        "x = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv2DTranspose(filters=64, kernel_size=3, strides=(2,2), padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv2DTranspose(filters=32, kernel_size=3, strides=(2,2), padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv2DTranspose(filters=16, kernel_size=3, strides=(2,2), padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv2DTranspose(filters=8, kernel_size=3, strides=(2,2), padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Output layer\n",
        "output_layer_heads = Conv2D(filters=1, kernel_size=1, activation='relu', kernel_initializer='he_uniform', name='heads_layer')(x)  #pointwise convolution\n",
        "output_layer_centroids = Conv2D(filters=1, kernel_size=1, activation='relu', kernel_initializer='he_uniform', name='centroids_layer')(x)\n",
        "\n",
        "# Defining the model\n",
        "model = keras.models.Model(inputs=input_layer, outputs=[output_layer_heads, output_layer_centroids])"
      ],
      "metadata": {
        "id": "tT8U78r4aOs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.0001), \n",
        "              loss={'heads_layer': 'mse',\n",
        "                    'centroids_layer': 'mse'})"
      ],
      "metadata": {
        "id": "UH1Px2MYabNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting\n",
        "no_epochs=12\n",
        "batch_size=3 \n",
        "history=model.fit(x=train_data, \n",
        "                  y={'heads_layer': gt_data_heads,\n",
        "                     'centroids_layer': gt_data_centroids}, \n",
        "                  validation_data=(validation_data, {'heads_layer': gt_validation_heads,\n",
        "                                                     'centroids_layer': gt_validation_centroids}),\n",
        "                  batch_size=batch_size, \n",
        "                  epochs=no_epochs, \n",
        "                  shuffle=True)"
      ],
      "metadata": {
        "id": "98wtnksHajUf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}