{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "import scipy\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from skimage.feature import peak_local_max"
      ],
      "metadata": {
        "id": "3ZkCr_znRfFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Metrics__\n",
        "##### Normalized MCME (Mean Coordinate Matching Error)"
      ],
      "metadata": {
        "id": "gv51xmupSO19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def diagonal(image):\n",
        "  \"\"\"Computes the diagonal of an image\"\"\"\n",
        "  d = (image.shape[0]**2 + image.shape[1]**2)**0.5\n",
        "  return d\n",
        "\n",
        "\n",
        "\n",
        "sqdiff = lambda xx,yy,diag: sum((x-y)**2 for x,y in zip(xx, yy))**0.5/diag # normalized distance\n",
        "\n",
        "\n",
        "\n",
        "def match(A, B):\n",
        "    NN = {}\n",
        "    for aa in A:\n",
        "        dist = {bb:sqdiff(aa,bb,diagonal(test_data[0])) for bb in B}\n",
        "        min_bb = min(dist, key=lambda bb: dist[bb])\n",
        "        NN[aa] = (min_bb, dist[min_bb])\n",
        "    #print(NN)\n",
        "    return NN\n",
        "\n",
        "\n",
        "\n",
        "def MCME2_ext(P, GT):\n",
        "    \"\"\"Computes MCME for the pair\"\"\"\n",
        "    m1 = match(P,GT)\n",
        "    m2 = match(GT,P)\n",
        "    \n",
        "    r1 = {(p,gt):d for (p,(gt,d)) in m1.items()}\n",
        "    r2 = {(p,gt):d for (gt,(p,d)) in m2.items()}\n",
        "    \n",
        "    r = {**r1, **r2}\n",
        "    return r, sum(r.values())/len(r)\n",
        "\n",
        "MCME2 = lambda P, GT: MCME2_ext(P,GT)[1]\n",
        "\n",
        "\n",
        "def Global_MCME(pred_centroids, gt_centroids): # Gets predicted centroids and ground truth centroids as input\n",
        "  \"\"\"Computes the average normalized MCME for all test images\"\"\"\n",
        "  import numpy as np\n",
        "  from skimage.feature import peak_local_max\n",
        "  MCME_list = []\n",
        "  counter = 0 # counts the images with no predicted centroids\n",
        "  assert len(gt_centroids) == len(pred_centroids)\n",
        "  for img_no in range(len(pred_centroids)):\n",
        "    coords_set_gt = set()\n",
        "    coords_set_pred = set()\n",
        "    gt_centroids_coords = peak_local_max(gt_centroids[img_no], min_distance=1)\n",
        "    pred_centroids_coords = peak_local_max(pred_centroids[img_no], min_distance=1)\n",
        "    for a in gt_centroids_coords:\n",
        "      coords_set_gt.add(tuple(a))\n",
        "    for a in pred_centroids_coords:\n",
        "      coords_set_pred.add(tuple(a))\n",
        "    if len(pred_centroids_coords) != 0:\n",
        "      MCME_list.append(MCME2(coords_set_pred, coords_set_gt))\n",
        "    else:\n",
        "      counter += 1\n",
        "  return (round(np.mean(MCME_list), 3), counter, MCME_list)"
      ],
      "metadata": {
        "id": "4ndOKhxLSOC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### MPPR (Multiple Patch Precision-Recall)"
      ],
      "metadata": {
        "id": "LfrkMcbpTQZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_patches(img_pred, img_gt, patch_x_width, patch_y_height):\n",
        "  \"\"\"Get the patches for a single image\"\"\"\n",
        "  random_start_w = np.random.randint(0, img_pred.shape[1])\n",
        "  random_start_h = np.random.randint(0, img_pred.shape[0])\n",
        "        \n",
        "  patch_array_pred = img_pred[random_start_h:random_start_h + patch_y_height, random_start_w:random_start_w + patch_x_width]\n",
        "  patch_array_gt = img_gt[random_start_h:random_start_h + patch_y_height, random_start_w:random_start_w + patch_x_width]\n",
        "        \n",
        "  return patch_array_pred, patch_array_gt\n",
        "\n",
        "\n",
        "\n",
        "def MPPR(pred, gt):\n",
        "  '''Computes the MPPR for a single image comparing\n",
        "  the predicted map and the ground truth map'''\n",
        "  TP = 0\n",
        "  TN = 0\n",
        "  FP = 0\n",
        "  FN = 0\n",
        "\n",
        "  if (pred.sum() != 0) and (gt.sum() != 0):\n",
        "    TP = 1\n",
        "  elif (pred.sum() == 0) and (gt.sum() != 0):\n",
        "    FN = 1\n",
        "  elif (pred.sum() != 0) and (gt.sum() == 0):\n",
        "    FP = 1\n",
        "  else:\n",
        "    TN = 1\n",
        "\n",
        "  return TP, TN, FP, FN\n",
        "\n",
        "\n",
        "\n",
        "def Global_MPPR(pred_data, gt_data, no_patches, width, height):\n",
        "  \"\"\"Computes the average MPPR for all test data\"\"\"\n",
        "  list_of_mean_precision = []\n",
        "  list_of_mean_recall = []\n",
        "\n",
        "  for img_pred, img_gt in zip(pred_data, gt_data):\n",
        "    list_TP = []\n",
        "    list_TN = []\n",
        "    list_FP = []\n",
        "    list_FN = []\n",
        "    for _ in range(no_patches):\n",
        "      a, b = get_patches(img_pred, img_gt, width, height)\n",
        "      TP, TN, FP, FN = MPPR(a, b)\n",
        "      list_TP.append(TP)\n",
        "      list_TN.append(TN)\n",
        "      list_FP.append(FP)\n",
        "      list_FN.append(FN)\n",
        "    TP_sum = np.sum(list_TP)\n",
        "    TN_sum = np.sum(list_TN)\n",
        "    FP_sum = np.sum(list_FP)\n",
        "    FN_sum = np.sum(list_FN)\n",
        "\n",
        "    recall = TP_sum / (TP_sum + FN_sum) \n",
        "    precision = TP_sum / (TP_sum + FP_sum)\n",
        "    \n",
        "    list_of_mean_precision.append(100 * round(precision, 4))\n",
        "    list_of_mean_recall.append(100 * round(recall, 4))\n",
        "\n",
        "  return list_of_mean_precision, list_of_mean_recall"
      ],
      "metadata": {
        "id": "XF5Ld623TVuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Filtering__"
      ],
      "metadata": {
        "id": "84pCYPx4XjDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_outputs(img, tau, sigma):\n",
        "  \"\"\"Thresholds the predicted map given a threshold tau\"\"\"\n",
        "  _, img_tau = cv2.threshold(img/img.max(), tau, 1.0, cv2.THRESH_TOZERO)\n",
        "  return scipy.ndimage.filters.gaussian_filter(img_tau, sigma=sigma)"
      ],
      "metadata": {
        "id": "9SdfHKjRXkv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Displacement__"
      ],
      "metadata": {
        "id": "c45FT8fhUXLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def displacement(x1, x2):\n",
        "  \"\"\"Computes the shift in two centroids vectors x1 and x2\"\"\"\n",
        "\n",
        "  import numpy as np\n",
        "\n",
        "  centroids_dict = {}\n",
        "\n",
        "  k, p = len(x1), len(x2)\n",
        "  D = np.zeros((k,p)) # The ij-th element in matrix D is the distance of the i-th centroid in x1 from the j-th centroid in x2\n",
        "  for i in range(k):\n",
        "    for j in range(p):\n",
        "      D[i,j] = np.linalg.norm(x2[j]-x1[i])\n",
        "\n",
        "  if len(x2) >= len(x1):\n",
        "\n",
        "    for elem in range(k): # for every row in matrix D\n",
        "      if (x2[np.argmin(D, axis=1)][elem][0] > x1[elem][0]) and (x2[np.argmin(D, axis=1)][elem][1] == x1[elem][1]):\n",
        "        out = 'EAST'\n",
        "      elif (x2[np.argmin(D, axis=1)][elem][0] < x1[elem][0]) and (x2[np.argmin(D, axis=1)][elem][1] == x1[elem][1]):\n",
        "        out = 'WEST'\n",
        "      elif (x2[np.argmin(D, axis=1)][elem][0] == x1[elem][0]) and (x2[np.argmin(D, axis=1)][elem][1] > x1[elem][1]):\n",
        "        out = 'NORTH'\n",
        "      elif (x2[np.argmin(D, axis=1)][elem][0] == x1[elem][0]) and (x2[np.argmin(D, axis=1)][elem][1] < x1[elem][1]):\n",
        "        out = 'SOUTH'\n",
        "      elif (x2[np.argmin(D, axis=1)][elem][0] > x1[elem][0]) and (x2[np.argmin(D, axis=1)][elem][1] > x1[elem][1]):\n",
        "        out = \"NORTH-EAST\"\n",
        "      elif (x2[np.argmin(D, axis=1)][elem][0] < x1[elem][0]) and (x2[np.argmin(D, axis=1)][elem][1] > x1[elem][1]):\n",
        "        out = \"NORTH-WEST\"\n",
        "      elif (x2[np.argmin(D, axis=1)][elem][0] > x1[elem][0]) and (x2[np.argmin(D, axis=1)][elem][1] < x1[elem][1]):\n",
        "        out = \"SOUTH-EAST\"\n",
        "      elif (x2[np.argmin(D, axis=1)][elem][0] < x1[elem][0]) and (x2[np.argmin(D, axis=1)][elem][1] < x1[elem][1]):\n",
        "        out = \"SOUTH-WEST\"\n",
        "      else:\n",
        "        out = 'NO MOVEMENT'\n",
        "      \n",
        "      distance = np.linalg.norm(x2[np.argmin(D, axis=1)][elem]-x1[elem])\n",
        "      centroids_dict[elem] = x1[elem], x2[np.argmin(D, axis=1)][elem], f'Dist = {round(distance,3)}', out\n",
        "\n",
        "  else:\n",
        "    k, p = len(x2), len(x1)\n",
        "    D = D.T\n",
        "\n",
        "    for elem in range(k):\n",
        "      if (x1[np.argmin(D, axis=1)][elem][0] > x2[elem][0]) and (x1[np.argmin(D, axis=1)][elem][1] == x2[elem][1]):\n",
        "        out = 'WEST'\n",
        "      elif (x1[np.argmin(D, axis=1)][elem][0] < x2[elem][0]) and (x1[np.argmin(D, axis=1)][elem][1] == x2[elem][1]):\n",
        "        out = 'EAST'\n",
        "      elif (x1[np.argmin(D, axis=1)][elem][0] == x2[elem][0]) and (x1[np.argmin(D, axis=1)][elem][1] > x2[elem][1]):\n",
        "        out = 'SOUTH'\n",
        "      elif (x1[np.argmin(D, axis=1)][elem][0] == x2[elem][0]) and (x1[np.argmin(D, axis=1)][elem][1] < x2[elem][1]):\n",
        "        out = 'NORTH'\n",
        "      elif (x1[np.argmin(D, axis=1)][elem][0] > x2[elem][0]) and (x1[np.argmin(D, axis=1)][elem][1] > x2[elem][1]):\n",
        "        out = \"SOUTH-WEST\"\n",
        "      elif (x1[np.argmin(D, axis=1)][elem][0] < x2[elem][0]) and (x1[np.argmin(D, axis=1)][elem][1] > x2[elem][1]):\n",
        "        out = \"SOUTH-EAST\"\n",
        "      elif (x1[np.argmin(D, axis=1)][elem][0] > x2[elem][0]) and (x1[np.argmin(D, axis=1)][elem][1] < x2[elem][1]):\n",
        "        out = \"NORTH-WEST\"\n",
        "      elif (x1[np.argmin(D, axis=1)][elem][0] < x2[elem][0]) and (x1[np.argmin(D, axis=1)][elem][1] < x2[elem][1]):\n",
        "        out = \"NORTH-EAST\"\n",
        "      else:\n",
        "        out = 'NO MOVEMENT'\n",
        "      \n",
        "      distance = np.linalg.norm(x2[elem]-x1[np.argmin(D, axis=1)][elem])\n",
        "      centroids_dict[elem] = x1[np.argmin(D, axis=1)][elem], x2[elem], f'Dist = {round(distance,3)}', out\n",
        "\n",
        "  return centroids_dict\n",
        "\n",
        "\n",
        "\n",
        "def prediction_and_displacement(model, t0, t1, tau):\n",
        "  \"\"\"Computes the displacement given two time instants t0 and t1\n",
        "  and given a threshold tau\"\"\"\n",
        "\n",
        "  inner_sigma = 10\n",
        "  displacement_list = []\n",
        "\n",
        "  a = np.expand_dims(test_data[t0], axis=0)\n",
        "  b = np.expand_dims(test_data[t1], axis=0)\n",
        "  img_t0 = model.predict(a)\n",
        "  img_t1 = model.predict(b)\n",
        "\n",
        "  if len(img_t0) == 2:\n",
        "    img_t0 = img_t0[1]\n",
        "    img_t1 = img_t1[1]\n",
        "\n",
        "  img_t0 = img_t0[0,:,:,0]\n",
        "  img_t1 = img_t1[0,:,:,0]\n",
        "\n",
        "  img_t0 = threshold_outputs(img=img_t0, tau=tau, sigma=inner_sigma)\n",
        "  img_t1 = threshold_outputs(img=img_t1, tau=tau, sigma=inner_sigma)\n",
        "\n",
        "  centroids_t0 = peak_local_max(img_t0, threshold_rel=.25)\n",
        "  centroids_t1 = peak_local_max(img_t1, threshold_rel=.25)\n",
        "\n",
        "  displacement_list.append(displacement(centroids_t0, centroids_t1))\n",
        "  \n",
        "  return displacement_list"
      ],
      "metadata": {
        "id": "YHsiTLL-UYNj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}